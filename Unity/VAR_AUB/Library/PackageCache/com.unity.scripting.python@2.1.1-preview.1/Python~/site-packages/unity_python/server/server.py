from __future__ import division, print_function

import sys
import time
import logging
import numbers
import os
import threading
import traceback
import utils

if sys.version_info.major < 3:
    import Queue as queue
    def fix_threading():
        # thread.get_ident moved to threading.get_ident in py3.3
        import thread
        threading.get_ident = thread.get_ident
    fix_threading()
else:
    import queue

import rpyc
import lockfile
import settings
from settings import process_jobs_max_batch_time

import logging
logger = logging.Logger("Unity Python server");
logger.addHandler(logging.StreamHandler(sys.stdout))

# Unbuffered print.
__print = print
def print(*args, **kwargs):
    __print(*args, **kwargs)
    f = kwargs.get('file', sys.stdout)
    if f is sys.stdout or f is sys.stderr:
        try:
            f.flush()
        except IOError:
            # Flushing fails if stdout/stderr is closed.
            pass

#####################
# The server is a singleton. We can't support multiple servers.
server = None

#####################
# We have a job system to allow threads to push work to the main thread.
# The main thread is the thread that called start_server.
# If we're already on the main thread, no need to delay!
main_thread_id = None

# This is the job queue. Add to it via jobs.put or call_on_main_thread.
# The main thread calls process_jobs every editor update (or every 2s in
# standalone mode) to process all outstanding jobs and then wait a bit longer
# for some fast replies.
jobs = queue.Queue()

#####################
# The server keeps track of all connections via on_connect so that it can
# notify them when we're shutting down or reloading.
# 'clients' is a map from name to a list of UnityService that match that name.
clients = dict()
clients_lock = threading.Lock()

#####################
# This connection delays some dispatching until the main thread gets to it.
# That's necessary for accessing some Unity objects. It's also a source of deadlocks,
# so we try to avoid delays if possible.

def call_on_main_thread(f):
    """
    Call a function on the main thread.
    Block until the main thread processes it.
    Return the value, or raise the exception it raised.
    """
    if threading.get_ident() == main_thread_id:
        print ("call on main thread: already on main thread")
        return f()

    condition = threading.Condition()
    return_value = []
    exception = []

    def job():
        with condition:
            try:
                return_value.append(f())
                print ("call on main thread: returning {}".format(str(return_value[0])))
            except:
                # Hand the exception to the other thread.
                exception.append(sys.exc_info()[1])
                print ("call on main thread: throwing {}".format(str(exception[0])))
            condition.notify()

    with condition:
        print ("call on main thread: send to main thread")
        jobs.put(job)
        condition.wait()
    if len(exception):
        raise exception[0]
    else:
        return return_value[0]

def _delay_if_not_root(f):
    def delayed(self, obj, *args):
        if obj is self._local_root:
            print("immediate call on connection")
            return f(self, obj, *args)
        else:
            print("delayed call")
            return call_on_main_thread(lambda: f(self, obj, *args))
    return delayed

class UnityConnection(rpyc.core.service.Connection):
    # Change how we handle some requests.
    # Calls into Unity mostly require they run on the main thread.
    # But many requests need to run on the current thread or we get deadlocks.

    def __init__(self, *args, **kwargs):
        super(UnityConnection, self).__init__(*args, **kwargs)

        # Keep track of some calls we can run on the worker thread.
        self._fast_calls = set([
                self._local_root.exposed_dict,
                self._local_root.exposed_list,
                self._local_root.exposed_import_module,
                self._local_root.exposed_log,
                ])
        try:
            import UnityEngine
            self._fast_calls.add(UnityEngine.Debug.Log)
            self._fast_calls.add(UnityEngine.Debug.LogWarning)
            self._fast_calls.add(UnityEngine.Debug.LogError)
        except ImportError: pass

        # Keep track of some types we can run on the worker thread.
        # TODO: make this go the other way -- discover what *can't* be run on worker thread.
        # Would be nice if we could optimize the case of getattr followed by call.
        d = dict()
        self._fast_callattr_types = set([
                dict,
                type(d.items()),
                type(d.keys()),
                type(d.__iter__()),
                set,
                type(set().__iter__()),
                list,
                type(list().__iter__()),
                tuple,
                type(tuple().__iter__()),
                ])
        if sys.version_info.major < 3:
            self._fast_callattr_types.add(type(d.iteritems()))
            self._fast_callattr_types.add(type(d.iterkeys()))

    def _handle_getattr(self, obj, name):
        if obj is self._local_root:
            print("getattr on root: {}".format(name))
            return getattr(obj, 'exposed_' + name)
        elif type(obj) in self._fast_callattr_types:
            print("getattr on fast object: {}.{}".format(type(obj), name))
            return getattr(obj, name)
        else:
            print("getattr on main thread: {}.{}".format(type(obj), name))
            job = lambda: super(UnityConnection, self)._handle_getattr(obj, name)
            return call_on_main_thread(job)

    # TODO: optimize these more. They're less performance-critical though.
    _handle_setattr = _delay_if_not_root(rpyc.core.service.Connection._handle_setattr)
    _handle_delattr = _delay_if_not_root(rpyc.core.service.Connection._handle_delattr)

    # Calls. Certain calls on the root we can optimize.
    def _handle_call(self, f, args, kwargs = ()):
        kwargs = dict(kwargs)

        try:
            # If f is a call we can fast-call, great!
            # But we can't be sure f is actually callable or hashable (could be a lambda)
            is_fast = f in self._fast_calls
        except TypeError:
            try:
                # Handle f as a constructor as well.
                is_fast = type(f) in self._fast_callattr_types
            except:
                is_fast = False

        if is_fast:
            print("handling fast-call {}".format(f))
            return f(*args, **kwargs)
        else:
            print("handling slow call {}".format(f))
            return call_on_main_thread(lambda: f(*args, **kwargs))

    # TODO: Call-attribute. This is just getattr + call. We can optimize that a lot by
    # testing once whether to delay, and if we delay, only create one job.
    def _handle_callattr(self, obj, name, args, kwargs=()):
        kwargs = dict(kwargs)
        if obj is self._local_root:
            # We can skip the usual rpyc name resolution and just use our own.
            if name == 'execute':
                print("handling root.execute on main thread")
                return call_on_main_thread(lambda: obj.exposed_execute(*args, **kwargs))
            else:
                print("handling fast callattr root.{}", name)
                f = getattr(obj, 'exposed_' + name)
                return f(*args, **kwargs)
        elif type(obj) in self._fast_callattr_types:
            print("handling fast callattr {}.{}".format(obj, name))
            f = getattr(obj, name)
            return f(*args, **kwargs)
        else:
            # We'll be doing a getattr and call. We can do this in a single job.
            print("handling slow callattr {}.{}".format(obj, name))
            def callattr():
                f = super(UnityConnection, self)._handle_getattr(obj, name)
                return f(*args, **kwargs)
            return call_on_main_thread(callattr)


#####################
# This server runs within Unity.
# There's a thread that runs a rpyc.utils.server.ThreadedServer
# Each connection gets its own thread.
# Each connection exposes:
#       execute -- exec on the Unity side.
#       import_module -- access a module on the Unity side.
#       log -- log in the Unity editor log and (for info/warning/error) in the Unity console
#       list, dict -- convenience functions to get a list or dict on the Unity side.
# For any object that's returned, we can access all public members.
#
# TODO: this is insecure in a multi-user setting. We need to require authentication.
class UnityService(rpyc.core.service.Service):
    _protocol = UnityConnection
    _shutting_down = False

    def on_connect(self, conn):
        name = conn.root.client_name()
        self._conn = conn
        self._client_name = name
        self._thread = threading.currentThread()
        with clients_lock:
            if name in clients:
                clients[name].append(self)
            else:
                clients[name] = [self]
        print("New client {} on thread {}".format(name, threading.get_ident()))

    def on_disconnect(self, conn):
        if self._shutting_down:
            return
        with clients_lock:
            try:
                if not hasattr(self, "_client_name"):
                    raise Exception("Disconnecting before connection completed")
                candidates = clients[self._client_name]
                candidates.remove(self)
                if len(candidates) == 0:
                    del clients[self._client_name]
            except:
                # log the error but don't let it stop us
                logging.exception("Exception while disconnecting:")

    def async_shutdown(self, is_rebooting):
        self._shutting_down = True
        shutdown = rpyc.async_(self._conn.root.on_server_shutdown)
        return shutdown(is_rebooting)

    def wait_for_thread(self):
        """
        After calling close(), call wait_for_thread() to wait until the thread is done.
        """
        self._thread.join()

    def exposed_list(self):
        return list()

    def exposed_dict(self):
        return dict()

    def exposed_execute(self, string, globals = None, filename = None):
        """
        Run some code.

        Returns None. If you want to get a value, have the string include code
        to set a variable, and read the `globals` dict.

        If set, `globals` must be a dict on the server, it cannot be a dict on the client.
        If `globals` is None, we create a new environment for each exec.
        """
        if filename is None:
            filename = self._client_name
        c = compile(string, filename = filename, mode = 'exec')
        if globals is None:
            globals = dict()
        exec(c, globals)

    def exposed_import_module(self, modulename):
        import importlib
        return importlib.import_module(modulename)

    def exposed_log(self, string, level=logging.INFO, traceback=None):
        message = "{}".format(string) 
        if traceback:
            message += """\nStack on client:\n{}""".format(traceback)
        utils.log(message, level)

def start_server():
    """
    Create the Unity server.

    Call this from the Unity main thread. We'll ensure that Unity functions are called on that thread.

    Returns True if the server was started, False if it was already running.
    """
    global server
    if server is not None:
        return False


    # Remember which thread is the main thread. This helps speed up calls later.
    global main_thread_id
    main_thread_id = threading.get_ident()
    logger.info("Unity Python server: main thread is {}".format(main_thread_id))

    global clients
    clients = dict()

    # Grab a lock file. If we fail, it's because there's another server trying to use the same path.
    lock = lockfile.lockfile(settings.unity_server_path + ".lock")

    # Remove the socket before we bind it. It might be left over from a prior crash.
    # Safe to remove here since we've got the lock.
    if os.path.exists(settings.unity_server_path):
        os.remove(settings.unity_server_path)

    config = { 'allow_public_attrs': True, 'allow_setattr': True }
    server = rpyc.ThreadedServer(UnityService, socket_path = settings.unity_server_path, protocol_config = config, logger = logger)
    server.lockfile = lock

    # Run the server on its own thread.
    server_thread = threading.Thread(target = server.start, name = 'Unity RPyC Server')
    server_thread.daemon = True
    server.thread = server_thread
    server_thread.start()
    return True

def is_server_active():
    return server is not None

def close_server(is_rebooting = False):
    """
    Close the Unity server and tell clients to react appropriately.

    Set `is_rebooting` to handle cases like domain reload when Unity is expected to come back shortly.

    Returns True if the server was closed by this call, False if it was already closed.
    """
    global server
    global clients

    if server is None:
        return False

    # Tell all the clients to quit.
    client_shutdown_async = []
    clients_to_shutdown = []
    with clients_lock:
        for client_list in clients.values():
            for c in client_list:
                try:
                    shutdown_result = c.async_shutdown(is_rebooting)
                    # Give the client a half-second to tell us there was a problem.
                    # If they don't tell us in that time, we just ignore the problem.
                    shutdown_result.set_expiry(0.5)
                    client_shutdown_async.append(shutdown_result)
                    clients_to_shutdown.append(c)
                except EOFError:
                    pass
    for a in client_shutdown_async:
        try:
            a.wait()
            a.value
        except EOFError:
            # The client shut down when we told it to shut down -- pretty normal.
            pass
        except:
            print("Exception while shutting down a client: {}".format(traceback.format_exc()))

    server.close()

    # Process all jobs pending. Client threads might be waiting for jobs to be
    # run on the main thread
    while not jobs.empty():
        process_jobs();

    server.thread.join()
    for c in clients_to_shutdown:
        c.wait_for_thread()

    # Finally release the lock file.
    server.lockfile.release()

    server = None
    clients = dict()
    return True

def process_jobs(batch_time = process_jobs_max_batch_time):
    """
    Call this from the main loop on every editor update.

    If there are any jobs to process, process them all and keep processing, or 
    wait for jobs for `batch_time` seconds, giving the clients time to send
    another request quickly if needed. The implication of this is at the last 
    milisecond, a job with a run time of 10 hours can be processed. The corollary
    is that a batch_time lower that the length of a job can be used to make sure 
    we process only one job.
    """

    if not isinstance(batch_time, numbers.Number):
        raise TypeError("'batch_time' argument must be numeric")
    
    # Looks like the threading model is co-operative. Yield back to the OS
    # so that the workers can work.
    time.sleep(0.001)

    global jobs
    if jobs.empty():
        return

    start = time.time()
    remaining = batch_time
    while remaining > 0:
        try:
            job = jobs.get(timeout=remaining)
            try:
                job()
            except EOFError:
                # we lost the connection to this client
                # ignore the problem, or do something about it? for now, ignore.
                pass

            jobs.task_done()
        except queue.Empty:
            break
        elapsed = (time.time() - start)
        remaining = batch_time - elapsed

def num_clients_connected(client_name):
    """
    Return the number of clients currently connected that have the given name.
    """
    with clients_lock:
        if client_name in clients:
            return len(clients[client_name])
        else:
            return 0

def get_connected_clients():
    """
    Return a list of the connected clients.
    """
    with clients_lock:
        return list(clients.keys())

def get_total_connected_clients():
    with clients_lock:
        return sum(len(v) for k,v in clients.items())

def get_rpyc_version():
    """
    Returns the version of rpyc as a string.
    """
    return str(rpyc.__version__)

def _call_service_on_client(async_, client_name, index, service_name, args = (), kwargs = {}):
    """
    Calls a service on a client.

    Clients are stored in order of connection time, but the only two indices
    likely to be useful are index 0 (the oldest) and index -1 (the newest).

    args should be a list
    kwargs should be a dict

    If async_ is True, then the returned type is rpyc.core.async_.AsyncResult. See: 
    https://rpyc.readthedocs.io/en/latest/api/core_netref.html#rpyc.core.async_.AsyncResult
    """
    with clients_lock:
        try:
            candidates = clients[client_name]
            client = candidates[index]
        except KeyError:
            raise KeyError("No client '{}' is connected".format(client_name))
        except IndexError:
            raise IndexError("Getting client '{}' [{}] but only {} are connected".format(client_name, index, len(candidates)))
    root = client._conn.root
    if args is None: args = []
    if kwargs is None: kwargs = {}
    
    if async_:
        func = rpyc.async_(getattr(root, service_name))
    else:
        func = getattr(root, service_name)
    return func(*args, **kwargs)

def call_service_on_client(client_name, index, service_name, args = (), kwargs = {}):
    """
    Calls a service on a client and waits until the client returns a value or 
    raises an exception or times out.

    args should be a list
    kwargs should be a dict
    """
    return _call_service_on_client(False, client_name, index, service_name, args, kwargs)

def call_service_on_client_async(client_name, index, service_name, args = (), kwargs = {}):
    """
    Calls a service on a client asynchronously.

    args should be a list
    kwargs should be a dict

    The returned type is rpyc.core.async_.AsyncResult. See: 
    https://rpyc.readthedocs.io/en/latest/api/core_netref.html#rpyc.core.async_.AsyncResult
    """
    return _call_service_on_client(True, client_name, index, service_name, args, kwargs)

def spawn_subpython(args, wantLogging = True, python_executable = sys.executable, env_override = {}):
    """
    Spawn a python subprocess.

    This is used to spawn the client, and it's used to check that the client will work.

    env_override is used to override the client environment. Set the variable as key
    and the value as the value fo the dict. Use a value of None to unset the environment
    variable

    Returns a Popen on success, and None on failure.
    """
    import subprocess
    args = [python_executable] + args

    # put our site-packages in the client's PYTHONPATH, using our own current location
    python_paths = [os.path.normpath(os.path.dirname(os.path.abspath(__file__)) + "/../..")]
    client_environment = dict(os.environ)
    if 'PYTHONPATH' in client_environment:
        python_paths.append(client_environment['PYTHONPATH'])
    client_environment['PYTHONPATH'] = os.pathsep.join(python_paths)

    # Make sure the client is doing unbuffered writes to stdout/stderr
    client_environment['PYTHONUNBUFFERED'] = "1"

    # Apply overrides to the client's environment
    for key, value in env_override.items():
        # if None, remove from environment
        if value is None:
            del client_environment[key]
        else:
            client_environment[key] = value

    # On python 2.7, ensure we only use ASCII strings.
    # os.environ/os.getenv() only returns ASCII, therefore any non-ASCII characters will either be approximated
    # or replaced with a question mark.
    # https://measureofchaos.wordpress.com/2011/03/04/python-on-windows-unicode-environment-variables/
    #
    # The problem should go away on python 3.x
    # https://stackoverflow.com/questions/12253014/why-does-popen-fail-on-windows-if-the-env-parameter-contains-a-unicode-object
    sys.stdout.write("env: " + client_environment.__str__()+ '\n')
    sys.stdout.flush()
    new_env = {}
    if sys.version_info.major < 3:
        for key, value in client_environment.iteritems(): 
            try:
                new_env[key.encode('ascii', 'strict')] = value.encode('ascii', 'strict')
            except UnicodeDecodeError:
                # We got UTF8 encoded into an ASCII string, decode first, then re-encode
                if sys.platform.startswith('win'):
                    encoding = 'mbcs'
                else :
                    encoding = 'utf-8'
                value = value.decode(encoding).encode('ascii', 'replace')
                key = key.decode(encoding).encode('ascii', 'replace')
                msg = 'Failed to properly convert the environment variable : {} with a value of: {}'\
                    .format(key, value)
                utils.log(msg, logging.INFO)

    if wantLogging:
        utils.log('Python for Unity: Creating client process: {} with PYTHONPATH={}'.format(' '.join(args), new_env['PYTHONPATH']))
    try:
        return subprocess.Popen(args, env=new_env, close_fds=True)
    except:
        if wantLogging:
            utils.log("""Could not launch the Python interpreter for the client process. Please refer to the com.unity.scripting.python documentation on how to configure Python for Unity. Stack on Client:\n{}""".format(traceback.format_exc()), logging.ERROR)
        return None

###########################################################################
## Test server.
## We need to import the module and send calls through there or we get two copies of the data.
if __name__ == '__main__':
    from server import *
    service_interval = 2
    timeout = 0.2
    print("Serving with a service interval of {}s and timeout of {}s".format(service_interval, timeout))

    start_server()
    try:
        while True:
            time.sleep(service_interval)
            process_jobs(timeout)
    except:
        traceback.print_exc()
    close_server()
    print("Closed the server; {} threads active".format(threading.active_count()))
