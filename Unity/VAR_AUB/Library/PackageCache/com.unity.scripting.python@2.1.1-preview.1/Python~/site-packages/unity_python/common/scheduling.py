#######
# EXPERIMENTAL API
# Use at your own risks
#######

import logging
import numbers
import sys
import threading
import time
import unity_python.server.utils as utils

from unity_python.server.settings import process_jobs_max_batch_time

if sys.version_info.major < 3:
    import Queue as queue
    def fix_threading():
        # thread.get_ident moved to threading.get_ident in py3.3
        import thread
        threading.get_ident = thread.get_ident
    fix_threading()
else:
    import queue


#####################
# We have a job system to allow threads to push work to the main thread.
# If we're already on the main thread, no need to delay!
main_thread_id = None

# This is the job queue. Add to it via jobs.put or call_on_main_thread.
# The main thread calls process_jobs every editor update (or every 2s in
# standalone mode) to process all outstanding jobs and then wait a bit longer
# for some fast replies.
jobs = queue.Queue()

def initialize():
    """
    Needs to be called from the main thread, before any job gets scheduled using
    call_on_main_thread
    """
    # Remember which thread is the main thread. This helps speed up calls later.
    global main_thread_id
    main_thread_id = threading.get_ident()
    print("Unity Python: main thread is {}".format(main_thread_id))

#####################
# This connection delays some dispatching until the main thread gets to it.
# That's necessary for accessing some Unity objects. It's also a source of deadlocks,
# so we try to avoid delays if possible.
def call_on_main_thread(f, wait_for_result = True):
    """
    Call a function on the main thread.
    
    If wait_for_result is True, will block until the main thread processes it 
    and return the value, or raise the exception it raised.

    If wait_for_result is False, then None is returned and exceptions will not 
    be raised
    """
    if wait_for_result and threading.get_ident() == main_thread_id:
        # Only execute (and block) if we're on the main thread and want to get 
        # the result/raise exceptions. Otherwise we just queue the job
        return f()

    condition = threading.Condition()
    return_value = []
    exception = []

    def job():
        with condition:
            try:
                return_value.append(f())
            except:
                # Hand the exception to the other thread.
                exception.append(sys.exc_info()[1])

                if not wait_for_result:
                    # raise the exception on the main thread as no one is 
                    # waiting on it
                    raise

            condition.notify()

    with condition:
        jobs.put(job)

        if wait_for_result:
            condition.wait()
            if len(exception):
                raise exception[0]
            else:
                return return_value[0]
        
        return None

def process_jobs(batch_time = process_jobs_max_batch_time):
    """
    Call this from the main loop on every editor update.

    If there are any jobs to process, process them all and keep processing, or 
    wait for jobs for `batch_time` seconds, giving the clients time to send
    another request quickly if needed. The implication of this is at the last 
    milisecond, a job with a run time of 10 hours can be processed. The corollary
    is that a batch_time lower that the length of a job can be used to make sure 
    we process only one job.
    """

    if not isinstance(batch_time, numbers.Number):
        raise TypeError("'batch_time' argument must be numeric")
    
    # The main thread always holds the GIL. Explicitly yield with a time.sleep
    # so other threads can push jobs in the jobs queue.
    time.sleep(0.001)

    global jobs
    if jobs.empty():
        return

    start = time.time()
    remaining = batch_time
    while remaining > 0:
        try:
            job = jobs.get(timeout=remaining)
            try:
                job()
            except EOFError:
                # we lost the connection to this client
                # ignore the problem, or do something about it? for now, ignore.
                pass

            jobs.task_done()
        except queue.Empty:
            break
        elapsed = (time.time() - start)
        remaining = batch_time - elapsed

def process_all_jobs():
    while not jobs.empty():
        process_jobs();

def exec_on_main_thread(f):
    """
    Decorator that will queue a job (function) for execution on the main thread.
    Returns when the job has been queued
    Does not provide a return value nor raises an exception if the queued job
    raises an exception
    """
    def func_wrapper(*args, **kwargs):
        call_on_main_thread(lambda: f(*args,**kwargs), wait_for_result=False)
    
    return func_wrapper
    
